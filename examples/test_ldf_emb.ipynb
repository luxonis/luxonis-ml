{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LuxonisDatasetFormat - testing embeddings methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import torchvision\n",
    "\n",
    "from qdrant_client.models import Distance\n",
    "\n",
    "from luxonis_ml.data import (\n",
    "    LuxonisDataset,\n",
    "    LuxonisLoader,\n",
    ")\n",
    "\n",
    "from luxonis_ml.embeddings.utils.model import (\n",
    "    load_model_resnet50_minuslastlayer,\n",
    "    export_model_onnx,\n",
    "    load_model_onnx,\n",
    "    extend_output_onnx,\n",
    "    load_model,\n",
    ")\n",
    "from luxonis_ml.embeddings.utils.embedding import (\n",
    "    extract_embeddings,\n",
    "    extract_embeddings_onnx,\n",
    "    save_embeddings,\n",
    "    load_embeddings,\n",
    ")\n",
    "from luxonis_ml.embeddings.utils.qdrant import QdrantManager, QdrantAPI\n",
    "from luxonis_ml.embeddings.utils.ldf import generate_embeddings\n",
    "\n",
    "from utils.data_utils import load_mnist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_loader = load_mnist_data(save_path=\"./mnist\", num_samples=640, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model_resnet50_minuslastlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from the dataset\n",
    "embeddings, labels = extract_embeddings(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings(embeddings, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX models and Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_loader = load_mnist_data(save_path=\"./mnist\", num_samples=640, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model()\n",
    "\n",
    "# Export the model to ONNX\n",
    "export_model_onnx(model, model_path_out=\"resnet50.onnx\")\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = load_model_onnx(model_path=\"resnet50.onnx\")\n",
    "\n",
    "# Extend the ONNX model with an intermediate output layer\n",
    "onnx_model = extend_output_onnx(\n",
    "    onnx_model, intermediate_tensor_name=\"/Flatten_output_0\"\n",
    ")\n",
    "\n",
    "# Save the ONNX model\n",
    "onnx.save(onnx_model, \"resnet50-1.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ONNX Runtime session\n",
    "provider = (\n",
    "    [\"CUDAExecutionProvider\"]\n",
    "    if torch.cuda.is_available()\n",
    "    and \"CUDAExecutionProvider\" in onnxruntime.get_available_providers()\n",
    "    else None\n",
    ")\n",
    "ort_session = onnxruntime.InferenceSession(\"resnet50-1.onnx\", providers=provider)\n",
    "\n",
    "# Extract embeddings from the dataset\n",
    "embeddings, labels = extract_embeddings_onnx(\n",
    "    ort_session, data_loader, \"/Flatten_output_0\"\n",
    ")\n",
    "\n",
    "# Save the embeddings and labels to a file\n",
    "save_embeddings(embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, labels = load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Qdrant docker container\n",
    "QdrantManager(\"qdrant/qdrant\", \"qdrant_container2\").start_docker_qdrant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Qdrant\n",
    "qdrant_api = QdrantAPI(\"localhost\", 6333, \"mnist2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a collection\n",
    "vector_size = embeddings.shape[1]\n",
    "qdrant_api.create_collection(vector_size=vector_size, distance=Distance.COSINE)\n",
    "\n",
    "# Insert the embeddings into the collection\n",
    "# qdrant_api.insert_embeddings(embeddings, labels)\n",
    "# qdrant_api.insert_embeddings_nooverwrite(embeddings, labels)\n",
    "qdrant_api.batch_insert_embeddings_nooverwrite(embeddings, labels, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the nearest neighbors\n",
    "search_results = qdrant_api.search_embeddings(embeddings[0], top=5)\n",
    "\n",
    "# Print the search results\n",
    "print(np.array(search_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LuxonisDatasetFormat, ONNX and Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(NUM_SAMPLES, train=0.8, val=0.1, test=0.1, seed=42):\n",
    "    if train + val + test != 1.0:\n",
    "        raise ValueError(\"TRAIN + VAL + TEST must equal 1.0\")\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    # generate random indices for train, val, test splits\n",
    "    indices = np.random.permutation(NUM_SAMPLES)\n",
    "    train_indices, val_indices, test_indices = (\n",
    "        indices[: int(train * NUM_SAMPLES)],\n",
    "        indices[int(train * NUM_SAMPLES) : int((train + val) * NUM_SAMPLES)],\n",
    "        indices[int((train + val) * NUM_SAMPLES) :],\n",
    "    )\n",
    "    train_test_val = np.array([\"train\"] * NUM_SAMPLES)\n",
    "    train_test_val[train_indices] = \"train\"\n",
    "    train_test_val[val_indices] = \"val\"\n",
    "    train_test_val[test_indices] = \"test\"\n",
    "\n",
    "    return train_test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 6400  # -1 # minus one is equivalent to all samples\n",
    "BATCH_SIZE = 64\n",
    "TRAIN, VAL, TEST = 0.8, 0.1, 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data\n",
    "data_loader = load_mnist_data(\n",
    "    save_path=\"./mnist\", num_samples=NUM_SAMPLES, batch_size=BATCH_SIZE\n",
    ")\n",
    "NUM_SAMPLES = len(data_loader.dataset)\n",
    "print(f\"Number of samples: {NUM_SAMPLES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, val, test\n",
    "train_test_val = train_test_val_split(NUM_SAMPLES, train=TRAIN, val=VAL, test=TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tmp directory to store the images\n",
    "mnist_image_dir = \"./mnist_images\"\n",
    "if not os.path.exists(mnist_image_dir):\n",
    "    os.makedirs(mnist_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MNIST data to Luxonis ML format\n",
    "\n",
    "def mnist_LDF_generator():\n",
    "    batch_num = 0\n",
    "    for batch in data_loader:\n",
    "        images, labels = batch\n",
    "        for i, (image, label) in enumerate(zip(images, labels)):\n",
    "            img_ix = batch_num * BATCH_SIZE + i\n",
    "\n",
    "            # Save image to disk\n",
    "            image_path = os.path.join(mnist_image_dir, f\"mnist_{img_ix}.jpg\")\n",
    "            torchvision.utils.save_image(image, image_path)\n",
    "\n",
    "            # Create dictionary structure for Luxonis ML\n",
    "            yield {\n",
    "                \"file\": image_path,\n",
    "                \"class\": str(label.item()),\n",
    "                \"type\": \"classification\",\n",
    "                \"value\": True,\n",
    "            }\n",
    "        batch_num += 1\n",
    "\n",
    "\n",
    "# original_additions = deepcopy(additions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the MNIST Data into LDF\n",
    "dataset_name = \"mnist_dataset\"\n",
    "\n",
    "# Create a new dataset in LDF\n",
    "dataset = LuxonisDataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the MNIST data to the dataset\n",
    "\n",
    "dataset.set_classes([\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])\n",
    "dataset.add(mnist_LDF_generator)\n",
    "dataset.make_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LuxonisLoader(dataset)\n",
    "for img, _ in loader:\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ONNX Runtime session for the model\n",
    "provider = (\n",
    "    [\"CUDAExecutionProvider\"]\n",
    "    if torch.cuda.is_available()\n",
    "    and \"CUDAExecutionProvider\" in onnxruntime.get_available_providers()\n",
    "    else None\n",
    ")\n",
    "ort_session = onnxruntime.InferenceSession(\"resnet50-1.onnx\", providers=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Qdrant docker container\n",
    "QdrantManager(\"qdrant/qdrant\", \"qdrant_container2\").start_docker_qdrant()\n",
    "\n",
    "# Connect to Qdrant\n",
    "qdrant_api = QdrantAPI(\"localhost\", 6333, \"mnist3\")\n",
    "\n",
    "# Create a collection\n",
    "qdrant_api.create_collection(vector_size=2048, distance=Distance.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LuxonisDataset\n",
    "emb_dict = generate_embeddings(\n",
    "    dataset, ort_session, qdrant_api, output_layer_name=\"/Flatten_output_0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_emb = None\n",
    "\n",
    "# get a specific sample from dataset\n",
    "first_sample = list(emb_dict.keys())[0]\n",
    "first_emb = emb_dict[first_sample]\n",
    "sample_id = first_sample\n",
    "\n",
    "# sample_id = '64e758bdca1096d3483d18f4'\n",
    "sample = dataset.fo_dataset[sample_id]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the nearest neighbors\n",
    "search_results = qdrant_api.search_embeddings(np.array(first_emb), top=5)\n",
    "print(np.array(search_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the test_emb_process.ipynb for the rest of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf ./mnist_images\n",
    "# ! rm -rf ./mnist\n",
    "# ! rm ./resnet50.onnx\n",
    "# ! rm ./resnet50-1.onnx\n",
    "# ! rm ./embeddings.pth\n",
    "# ! rm ./labels.pth\n",
    "\n",
    "# # # Stop the Qdrant Docker container\n",
    "# # stop_docker_qdrant()\n",
    "\n",
    "# # Delete the Qdrant collection\n",
    "# qdrant_client.delete_collection(collection_name=\"mnist2\")\n",
    "# qdrant_client.delete_collection(collection_name=\"mnist3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete the Luxonis ML dataset\n",
    "\n",
    "# dataset.delete_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
