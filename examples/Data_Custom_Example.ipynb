{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9de6101",
   "metadata": {},
   "source": [
    "## Adding COCO Data Using Custom Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from luxonis_ml.data import LuxonisDataset, LuxonisLoader, DatasetIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3a45c-7152-41a8-9ebf-db54cb84edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "\n",
    "dataset_name = \"coco_test\"\n",
    "dataset = LuxonisDataset(dataset_name, delete_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c2791",
   "metadata": {},
   "source": [
    "### Download and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9ddf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/uc?id=1XlvFK7aRmt8op6-hHkWVKIJQeDtOwoRT\"\n",
    "output_zip = \"../data/COCO_people_subset.zip\"\n",
    "output_folder = \"../data/\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.exists(output_zip):\n",
    "    gdown.download(url, output_zip, quiet=False)\n",
    "\n",
    "with zipfile.ZipFile(output_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15dfc38",
   "metadata": {},
   "source": [
    "### Converting from COCO People Subset  \n",
    "\n",
    "`LuxonisDataset` expects a generator yielding dictionary of data for each instance in the following format:  \n",
    "\n",
    "- **file** (*str*): Path to the image file.  \n",
    "- **annotation** (*Optional[dict]*): Contains annotations for a single instance:  \n",
    "  - **class** (*str*): Object label (e.g., `\"person\"`).  \n",
    "  - **boundingbox** (*dict*): Normalized bounding box (0-1 scale).  \n",
    "    - **x, y** (*float*): Top-left coordinates.  \n",
    "    - **w, h** (*float*)_ Width and height.  \n",
    "  - **segmentation** (*dict*): Object mask in **polygon** or **RLE** format.  \n",
    "    - **Polygon**:  \n",
    "      - **height, width** (*int*): Image dimensions.  \n",
    "      - **points** (*List[Tuple[float, float]]*): List of normalized `(x, y)` coordinates.  \n",
    "    - **RLE**:  \n",
    "      - **height, width** (*int*): Image dimensions.  \n",
    "      - **counts** (*List[int]*): Run-length encoded mask.  \n",
    "  - **instance_segmentation** (*dict*): Instance segmentation mask (same format as segmentation).  \n",
    "    - **Polygon**:  \n",
    "      - **height, width** (*int*): Image dimensions.  \n",
    "      - **points** (*List[Tuple[float, float]]*): List of normalized `(x, y)` coordinates.  \n",
    "    - **RLE**:  \n",
    "      - **height, width** (*int*): Image dimensions.  \n",
    "      - **counts** (*List[int]*): Run-length encoded mask. \n",
    "  - **keypoints** (*dict*): Ordered list of normalized keypoints.  \n",
    "    - **keypoints**(*List[Tuple[float, float, int]]*): Each keypoint as `(x, y, visibility)`, where:   \n",
    "      - `x, y` (*float*): Normalized keypoint coordinates.  \n",
    "      - **visibility** (*int*):  \n",
    "        - `0`: Not visible  \n",
    "        - `1`: Occluded  \n",
    "        - `2`: Fully visible \n",
    "\n",
    "\n",
    "> If you yield bounding boxes, keypoints, and instance segmentation masks separately for the same object, ensure that `instance_id` is included in each annotation type to maintain proper association.\n",
    "**instance_id** (*Optional[int]*) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def COCO_people_subset_generator() -> DatasetIterator:\n",
    "    # find image paths and load COCO annotations\n",
    "    img_dir = \"../data/person_val2017_subset\"\n",
    "    annot_file = \"../data/person_keypoints_val2017.json\"\n",
    "    # get paths to images sorted by number\n",
    "    im_paths = glob.glob(os.path.join(img_dir, \"*.jpg\"))\n",
    "    nums = np.array(\n",
    "        [int(os.path.splitext(os.path.basename(path))[0]) for path in im_paths]\n",
    "    )\n",
    "    idxs = np.argsort(nums)\n",
    "    im_paths = list(np.array(im_paths)[idxs])\n",
    "    # load\n",
    "    with open(annot_file) as file:\n",
    "        data = json.load(file)\n",
    "    imgs = data[\"images\"]\n",
    "    anns = data[\"annotations\"]\n",
    "    # Create dictionaries for quick lookups\n",
    "    img_dict = {img[\"file_name\"]: img for img in imgs}\n",
    "    ann_dict = {}\n",
    "    for ann in anns:\n",
    "        img_id = ann[\"image_id\"]\n",
    "        if img_id not in ann_dict:\n",
    "            ann_dict[img_id] = []\n",
    "        ann_dict[img_id].append(ann)\n",
    "\n",
    "    # Process each image and its annotations\n",
    "    for path in tqdm(im_paths):\n",
    "        # Find annotations matching the COCO image\n",
    "        gran = os.path.basename(path)\n",
    "        img = img_dict.get(gran)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_id = img[\"id\"]\n",
    "        img_anns = ann_dict.get(img_id, [])\n",
    "\n",
    "        # Load the image\n",
    "        im = cv2.imread(path)\n",
    "        height, width, _ = im.shape\n",
    "\n",
    "        # First yield just the file\n",
    "        yield {\"file\": path}\n",
    "\n",
    "        # Process each annotation\n",
    "        for i, ann in enumerate(img_anns):\n",
    "            # Create a base record with the file and instance ID\n",
    "            record = {\n",
    "                \"file\": path,\n",
    "                \"annotation\": {\n",
    "                    \"class\": \"person\",\n",
    "                    \"instance_id\": i,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # Add bounding box to record\n",
    "            x, y, w, h = ann[\"bbox\"]\n",
    "            record[\"annotation\"][\"boundingbox\"] = {\n",
    "                \"x\": x / width,\n",
    "                \"y\": y / height,\n",
    "                \"w\": w / width,\n",
    "                \"h\": h / height,\n",
    "            }\n",
    "\n",
    "            # Process segmentation\n",
    "            seg = ann[\"segmentation\"]\n",
    "            if isinstance(seg, list) and seg:  # polygon format\n",
    "                poly = []\n",
    "                for s in seg:\n",
    "                    poly_arr = np.array(s).reshape(-1, 2)\n",
    "                    poly += [\n",
    "                        (poly_arr[j, 0] / width, poly_arr[j, 1] / height)\n",
    "                        for j in range(len(poly_arr))\n",
    "                    ]\n",
    "                segmentation = {\n",
    "                    \"height\": height,\n",
    "                    \"width\": width,\n",
    "                    \"points\": poly,\n",
    "                }\n",
    "                record[\"annotation\"][\"segmentation\"] = segmentation\n",
    "                record[\"annotation\"][\"instance_segmentation\"] = segmentation\n",
    "            elif isinstance(seg, dict):  # RLE format\n",
    "                segmentation = {\n",
    "                    \"height\": seg[\"size\"][0],\n",
    "                    \"width\": seg[\"size\"][1],\n",
    "                    \"counts\": seg[\"counts\"],\n",
    "                }\n",
    "                record[\"annotation\"][\"segmentation\"] = segmentation\n",
    "                record[\"annotation\"][\"instance_segmentation\"] = segmentation\n",
    "\n",
    "            # Add keypoints to record\n",
    "            if \"keypoints\" in ann:\n",
    "                kps = np.array(ann[\"keypoints\"]).reshape(-1, 3)\n",
    "                keypoints = []\n",
    "                for kp in kps:\n",
    "                    # Clip keypoints to image boundaries\n",
    "                    x = np.clip(kp[0], 0, width)\n",
    "                    y = np.clip(kp[1], 0, height)\n",
    "                    keypoints.append((x / width, y / height, int(kp[2])))\n",
    "                record[\"annotation\"][\"keypoints\"] = {\"keypoints\": keypoints}\n",
    "\n",
    "            # Yield the complete record with all annotations\n",
    "            yield record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LuxonisDataset(dataset_name)\n",
    "dataset.add(COCO_people_subset_generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9454797-d804-45f1-92dc-393f76be2219",
   "metadata": {},
   "source": [
    "### Define Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2094a5d-0371-48da-91f1-b9590686339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without providing manual definitions, this will randomly split the data\n",
    "dataset.make_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6d36-d5f1-4c68-9f70-80d26d45690e",
   "metadata": {},
   "source": [
    "### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda91cd6-9fe5-43ee-ab88-3dfc57ff89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LuxonisLoader(dataset, view=\"train\")\n",
    "for image, ann in loader:\n",
    "    cls = ann[\"/classification\"]\n",
    "    box = ann[\"/boundingbox\"]\n",
    "    seg = ann[\"/segmentation\"]\n",
    "    kps = ann[\"/keypoints\"]\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    for b in box:\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(b[1] * w), int(b[2] * h)),\n",
    "            (int(b[1] * w + b[3] * w), int(b[2] * h + b[4] * h)),\n",
    "            (255, 0, 0),\n",
    "            2,\n",
    "        )\n",
    "    mask_viz = np.zeros((h, w, 3)).astype(np.uint8)\n",
    "    for mask in seg:\n",
    "        mask_viz[mask == 1, 2] = 255\n",
    "    image = cv2.addWeighted(image, 0.5, mask_viz, 0.5, 0)\n",
    "\n",
    "    for kp in kps:\n",
    "        kp = kp.reshape(-1, 3)\n",
    "        for k in kp:\n",
    "            cv2.circle(\n",
    "                image, (int(k[0] * w), int(k[1] * h)), 2, (0, 255, 0), 2\n",
    "            )\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Optional: Hide axis\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
