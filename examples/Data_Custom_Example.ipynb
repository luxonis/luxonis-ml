{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9de6101",
   "metadata": {},
   "source": [
    "## Adding COCO Data Using Custom Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import cv2\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from luxonis_ml.data import LuxonisDataset, LuxonisLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3a45c-7152-41a8-9ebf-db54cb84edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataset if exists\n",
    "\n",
    "dataset_name = \"coco_test\"\n",
    "if LuxonisDataset.exists(dataset_name):\n",
    "    dataset = LuxonisDataset(dataset_name)\n",
    "    dataset.delete_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c2791",
   "metadata": {},
   "source": [
    "### Download and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9ddf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/uc?id=1XlvFK7aRmt8op6-hHkWVKIJQeDtOwoRT\"\n",
    "output_zip = \"../data/COCO_people_subset.zip\"\n",
    "output_folder = \"../data/\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.exists(output_zip):\n",
    "    gdown.download(url, output_zip, quiet=False)\n",
    "\n",
    "with zipfile.ZipFile(output_zip, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2befa6b3",
   "metadata": {},
   "source": [
    "### Convert from COCO people subset example\n",
    "\n",
    "`LuxonisDataset` will expect a generator that yields data in the following format:\n",
    "```\n",
    "- file [str] : path to file on local disk or object storage\n",
    "- class [str]: string specifying the class name or label name\n",
    "- type [str] : the type of label or annotation\n",
    "- value [Union[str, list, int, float, bool]]: the actual annotation value\n",
    "    For here are the expected structures for `value`.\n",
    "    The function will check to ensure `value` matches this for each annotation type\n",
    "\n",
    "    value (classification) [bool] : Marks whether the class is present or not\n",
    "        (e.g. True/False)\n",
    "    value (box) [List[float]] : the normalized (0-1) x, y, w, and h of a bounding box\n",
    "        (e.g. [0.5, 0.4, 0.1, 0.2])\n",
    "    value (polyline) [List[List[float]]] : an ordered list of [x, y] polyline points\n",
    "        (e.g. [[0.2, 0.3], [0.4, 0.5], ...])\n",
    "    value (segmentation) [Tuple[int, int, List[int]]]: an RLE representation of (height, width, counts) based on the COCO convention\n",
    "    value (keypoints) [List[List[float]]] : an ordered list of [x, y, visibility] keypoints for a keypoint skeleton instance\n",
    "        (e.g. [[0.2, 0.3, 2], [0.4, 0.5, 2], ...])\n",
    "    value (array) [str]: path to a numpy .npy file\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def COCO_people_subset_generator():\n",
    "    # find image paths and load COCO annotations\n",
    "    img_dir = \"../data/person_val2017_subset\"\n",
    "    annot_file = \"../data/person_keypoints_val2017.json\"\n",
    "    # get paths to images sorted by number\n",
    "    im_paths = glob.glob(os.path.join(img_dir, \"*.jpg\"))\n",
    "    nums = np.array(\n",
    "        [int(os.path.splitext(os.path.basename(path))[0]) for path in im_paths]\n",
    "    )\n",
    "    idxs = np.argsort(nums)\n",
    "    im_paths = list(np.array(im_paths)[idxs])\n",
    "    # load\n",
    "    with open(annot_file) as file:\n",
    "        data = json.load(file)\n",
    "    imgs = data[\"images\"]\n",
    "    anns = data[\"annotations\"]\n",
    "    # Create dictionaries for quick lookups\n",
    "    img_dict = {img[\"file_name\"]: img for img in imgs}\n",
    "    ann_dict = {}\n",
    "    for ann in anns:\n",
    "        img_id = ann[\"image_id\"]\n",
    "        if img_id not in ann_dict:\n",
    "            ann_dict[img_id] = []\n",
    "        ann_dict[img_id].append(ann)\n",
    "\n",
    "    # Process each image and its annotations\n",
    "    for path in tqdm(im_paths):\n",
    "        # Find annotations matching the COCO image\n",
    "        gran = os.path.basename(path)\n",
    "        img = img_dict.get(gran, None)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_id = img[\"id\"]\n",
    "        img_anns = ann_dict.get(img_id, [])\n",
    "\n",
    "        # Load the image\n",
    "        im = cv2.imread(path)\n",
    "        height, width, _ = im.shape\n",
    "\n",
    "        if len(img_anns):\n",
    "            yield {\n",
    "                \"file\": path,\n",
    "                \"annotation\": {\n",
    "                    \"type\": \"classification\",\n",
    "                    \"class\": \"person\",\n",
    "                },\n",
    "            }\n",
    "\n",
    "        for i, ann in enumerate(img_anns):\n",
    "            # COCO-specific conversion for segmentation\n",
    "            seg = ann[\"segmentation\"]\n",
    "            if isinstance(seg, list):  # polyline format\n",
    "                poly = []\n",
    "                for s in seg:\n",
    "                    poly_arr = np.array(s).reshape(-1, 2)\n",
    "                    poly += [\n",
    "                        (poly_arr[i, 0] / width, poly_arr[i, 1] / height)\n",
    "                        for i in range(len(poly_arr))\n",
    "                    ]\n",
    "                yield {\n",
    "                    \"file\": path,\n",
    "                    \"annotation\": {\n",
    "                        \"type\": \"polyline\",\n",
    "                        \"class\": \"person\",\n",
    "                        \"points\": poly,\n",
    "                    },\n",
    "                }\n",
    "\n",
    "            else:  # RLE format\n",
    "                yield {\n",
    "                    \"file\": path,\n",
    "                    \"annotation\": {\n",
    "                        \"type\": \"rle\",\n",
    "                        \"class\": \"person\",\n",
    "                        \"height\": seg[\"size\"][0],\n",
    "                        \"width\": seg[\"size\"][1],\n",
    "                        \"counts\": seg[\"counts\"],\n",
    "                    },\n",
    "                }\n",
    "\n",
    "            # COCO-specific conversion for bounding boxes\n",
    "            x, y, w, h = ann[\"bbox\"]\n",
    "            yield {\n",
    "                \"file\": path,\n",
    "                \"annotation\": {\n",
    "                    \"type\": \"boundingbox\",\n",
    "                    \"instance_id\": i,\n",
    "                    \"class\": \"person\",\n",
    "                    \"x\": x / width,\n",
    "                    \"y\": y / height,\n",
    "                    \"w\": w / width,\n",
    "                    \"h\": h / height,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # COCO-specific conversion for keypoints\n",
    "            kps = np.array(ann[\"keypoints\"]).reshape(-1, 3)\n",
    "            keypoints = []\n",
    "            for kp in kps:\n",
    "                keypoints.append(\n",
    "                    (float(kp[0] / width), float(kp[1] / height), int(kp[2]))\n",
    "                )\n",
    "            yield {\n",
    "                \"file\": path,\n",
    "                \"annotation\": {\n",
    "                    \"type\": \"keypoints\",\n",
    "                    \"instance_id\": i,\n",
    "                    \"class\": \"person\",\n",
    "                    \"keypoints\": keypoints,\n",
    "                },\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LuxonisDataset(dataset_name)\n",
    "annot_file = \"../data/person_keypoints_val2017.json\"\n",
    "with open(annot_file) as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "dataset.set_skeletons(\n",
    "    {\n",
    "        \"person\": {\n",
    "            \"labels\": data[\"categories\"][0][\"keypoints\"],\n",
    "            \"edges\": (\n",
    "                np.array(data[\"categories\"][0][\"skeleton\"]) - 1\n",
    "            ).tolist(),\n",
    "        }\n",
    "    },\n",
    "    task=\"keypoints\",\n",
    ")\n",
    "\n",
    "dataset.add(COCO_people_subset_generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9454797-d804-45f1-92dc-393f76be2219",
   "metadata": {},
   "source": [
    "### Define Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2094a5d-0371-48da-91f1-b9590686339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without providing manual splits, this will randomly split the data\n",
    "dataset.make_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6d36-d5f1-4c68-9f70-80d26d45690e",
   "metadata": {},
   "source": [
    "### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda91cd6-9fe5-43ee-ab88-3dfc57ff89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LuxonisLoader(dataset, view=\"train\")\n",
    "for image, ann in loader:\n",
    "    cls = ann[\"classification\"][0]\n",
    "    box = ann[\"boundingbox\"][0]\n",
    "    seg = ann[\"segmentation\"][0]\n",
    "    kps = ann[\"keypoints\"][0]\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    for b in box:\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (int(b[1] * w), int(b[2] * h)),\n",
    "            (int(b[1] * w + b[3] * w), int(b[2] * h + b[4] * h)),\n",
    "            (255, 0, 0),\n",
    "            2,\n",
    "        )\n",
    "    mask_viz = np.zeros((h, w, 3)).astype(np.uint8)\n",
    "    for mask in seg:\n",
    "        mask_viz[mask == 1, 2] = 255\n",
    "    image = cv2.addWeighted(image, 0.5, mask_viz, 0.5, 0)\n",
    "\n",
    "    for kp in kps:\n",
    "        kp = kp[1:].reshape(-1, 3)\n",
    "        for k in kp:\n",
    "            cv2.circle(\n",
    "                image, (int(k[0] * w), int(k[1] * h)), 2, (0, 255, 0), 2\n",
    "            )\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")  # Optional: Hide axis\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
