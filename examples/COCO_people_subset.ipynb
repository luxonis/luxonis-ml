{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9de6101",
   "metadata": {},
   "source": [
    "## Adding a subset of COCO people data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, json, os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from luxonis_ml.data import *\n",
    "from luxonis_ml.enums import LabelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3a45c-7152-41a8-9ebf-db54cb84edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete dataset if exists\n",
    "\n",
    "dataset_name = \"coco_test\"\n",
    "if LuxonisDataset.exists(dataset_name):\n",
    "    dataset = LuxonisDataset(dataset_name)\n",
    "    dataset.delete_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c2791",
   "metadata": {},
   "source": [
    "### Download and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9ddf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install gdown\n",
    "! gdown 1XlvFK7aRmt8op6-hHkWVKIJQeDtOwoRT -O ../data/COCO_people_subset.zip\n",
    "! unzip ../data/COCO_people_subset.zip -d ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2befa6b3",
   "metadata": {},
   "source": [
    "### Convert from COCO people subset example\n",
    "\n",
    "`LuxonisDataset` will expect a generator that yields data in the following format:\n",
    "```\n",
    "- file [str] : path to file on local disk or object storage\n",
    "- class [str]: string specifying the class name or label name\n",
    "- type [str] : the type of label or annotation\n",
    "- value [Union[str, list, int, float, bool]]: the actual annotation value\n",
    "    For here are the expected structures for `value`.\n",
    "    The function will check to ensure `value` matches this for each annotation type\n",
    "\n",
    "    value (classification) [bool] : Marks whether the class is present or not\n",
    "        (e.g. True/False)\n",
    "    value (box) [List[float]] : the normalized (0-1) x, y, w, and h of a bounding box\n",
    "        (e.g. [0.5, 0.4, 0.1, 0.2])\n",
    "    value (polyline) [List[List[float]]] : an ordered list of [x, y] polyline points\n",
    "        (e.g. [[0.2, 0.3], [0.4, 0.5], ...])\n",
    "    value (segmentation) [Tuple[int, int, List[int]]]: an RLE representation of (height, width, counts) based on the COCO convention\n",
    "    value (keypoints) [List[List[float]]] : an ordered list of [x, y, visibility] keypoints for a keypoint skeleton instance\n",
    "        (e.g. [[0.2, 0.3, 2], [0.4, 0.5, 2], ...])\n",
    "    value (array) [str]: path to a numpy .npy file\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create some artificial splits\n",
    "# splits = ['train' for _ in range(20)] + ['val' for _ in range(10)]\n",
    "\n",
    "def COCO_people_subset_generator():\n",
    "\n",
    "    # find image paths and load COCO annotations\n",
    "    img_dir = '../data/person_val2017_subset'\n",
    "    annot_file = '../data/person_keypoints_val2017.json'\n",
    "    # get paths to images sorted by number\n",
    "    im_paths = glob.glob(img_dir+'/*.jpg')\n",
    "    nums = np.array([int(path.split('/')[-1].split('.')[0]) for path in im_paths])\n",
    "    idxs = np.argsort(nums)\n",
    "    im_paths = list(np.array(im_paths)[idxs])\n",
    "    # load \n",
    "    with open(annot_file) as file:\n",
    "        data = json.load(file)\n",
    "    imgs = data['images']\n",
    "    anns = data['annotations']\n",
    "    \n",
    "    for i, path in tqdm(enumerate(im_paths)):\n",
    "        # find annotations matching the COCO image\n",
    "        gran = path.split('/')[-1]\n",
    "        img = [img for img in imgs if img['file_name']==gran][0]\n",
    "        img_id = img['id']\n",
    "        img_anns = [ann for ann in anns if ann['image_id'] == img_id]\n",
    "        \n",
    "        # load the image\n",
    "        im = cv2.imread(path)\n",
    "        height, width, _ = im.shape\n",
    "        \n",
    "        # initialize annotations for LDF\n",
    "        mask = np.zeros((height, width)) # segmentation mask is always a HxW numpy array\n",
    "        boxes = [] # bounding boxes are a list of [class, x, y, width, height] of the box\n",
    "        keypoints = [] # keypoints are a list of classes and (x,y) points\n",
    "    \n",
    "        if len(img_anns):\n",
    "            yield {\n",
    "                \"file\": path,\n",
    "                \"class\": \"person\",\n",
    "                \"type\": \"classification\",\n",
    "                \"value\": True\n",
    "            }\n",
    "        \n",
    "        for ann in img_anns:\n",
    "            # COCO-specific conversion for segmentation\n",
    "            seg = ann['segmentation']\n",
    "            if isinstance(seg, list): # polyline format\n",
    "                poly = []\n",
    "                for s in seg:\n",
    "                    poly_arr = np.array(s).reshape(-1,2)\n",
    "                    poly += [[poly_arr[i,0]/width, poly_arr[i,1]/height] for i in range(len(poly_arr))]\n",
    "                yield {\n",
    "                    \"file\": path,\n",
    "                    \"class\": \"person\",\n",
    "                    \"type\": \"polyline\",\n",
    "                    \"value\": poly\n",
    "                }\n",
    "            else: # RLE format\n",
    "                height, width = seg[\"size\"]\n",
    "                rle = mask_utils.frPyObjects(seg, height, width)\n",
    "\n",
    "                value = (rle[\"size\"][0], rle[\"size\"][1], list(rle[\"counts\"]))\n",
    "                yield {\n",
    "                    \"file\": path,\n",
    "                    \"class\": \"person\",\n",
    "                    \"type\": \"segmentation\",\n",
    "                    \"value\": value\n",
    "                }\n",
    "                \n",
    "            \n",
    "            # COCO-specific conversion for bounding boxes\n",
    "            x, y, w, h = ann['bbox']\n",
    "            yield {\n",
    "                \"file\": path,\n",
    "                \"class\": \"person\",\n",
    "                \"type\": \"box\",\n",
    "                \"value\": [x/width, y/height, w/width, h/height]\n",
    "            }\n",
    "            \n",
    "            # COCO-specific conversion for keypoints\n",
    "            kps = np.array(ann['keypoints']).reshape(-1, 3)\n",
    "            keypoint = []\n",
    "            for kp in kps:\n",
    "                keypoint.append([float(kp[0]/width), float(kp[1]/height), int(kp[2])])  \n",
    "            yield {\n",
    "                \"file\": path,\n",
    "                \"class\": \"person\",\n",
    "                \"type\": \"keypoints\",\n",
    "                \"value\": keypoint\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8171a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LuxonisDataset(dataset_name)\n",
    "dataset.set_classes([\"person\"])\n",
    "\n",
    "annot_file = '../data/person_keypoints_val2017.json'\n",
    "with open(annot_file) as file:\n",
    "    data = json.load(file)\n",
    "dataset.set_skeletons({\n",
    "    \"person\": {\n",
    "        \"labels\": data[\"categories\"][0]['keypoints'],\n",
    "        \"edges\": (np.array(data[\"categories\"][0][\"skeleton\"])-1).tolist()\n",
    "    }\n",
    "})\n",
    "dataset.add(COCO_people_subset_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9454797-d804-45f1-92dc-393f76be2219",
   "metadata": {},
   "source": [
    "### Define Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2094a5d-0371-48da-91f1-b9590686339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without providing manual splits, this will randomly split the data\n",
    "dataset.make_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6d36-d5f1-4c68-9f70-80d26d45690e",
   "metadata": {},
   "source": [
    "### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda91cd6-9fe5-43ee-ab88-3dfc57ff89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = LuxonisLoader(dataset, view=\"train\")\n",
    "for image, ann in loader:\n",
    "    cls = ann[LabelType.CLASSIFICATION]\n",
    "    box = ann[LabelType.BOUNDINGBOX]\n",
    "    seg = ann[LabelType.SEGMENTATION]\n",
    "    kps = ann[LabelType.KEYPOINT]\n",
    "    \n",
    "    # print(\"Sample classification tensor\")\n",
    "    # print(cls)\n",
    "    # print()\n",
    "\n",
    "    # print(\"Sample boxes tensor\")\n",
    "    # print(box)\n",
    "    # print()\n",
    "\n",
    "    # print(\"Sample segmentation tensor\")\n",
    "    # print(seg)\n",
    "    # print()\n",
    "\n",
    "    # print(\"Sample keypoints tensor\")\n",
    "    # print(kps)\n",
    "    # print()\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    for b in box:\n",
    "        cv2.rectangle(image, (int(b[1]*w),int(b[2]*h)), (int(b[1]*w+b[3]*w),int(b[2]*h+b[4]*h)), (255,0,0), 2)\n",
    "    mask_viz = np.zeros((h,w,3)).astype(np.uint8)\n",
    "    for mask in seg:\n",
    "        mask_viz[mask==1, 2] = 255\n",
    "    image = cv2.addWeighted(image, 0.5, mask_viz, 0.5, 0)\n",
    "\n",
    "    for kp in kps:\n",
    "        kp = kp[1:].reshape(-1,3)\n",
    "        for k in kp:\n",
    "            cv2.circle(image, (int(k[0]*w),int(k[1]*h)), 2, (0,255,0), 2)\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Optional: Hide axis\n",
    "    plt.show()\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
